import json
import csv
import os
from collections import defaultdict

# === è¨­å®šç›®æ¨™è³¦å®¶ ===
target_author = "ç‹èµ·"

# === æª”æ¡ˆè·¯å¾‘ ===
main_json_path = r"D:\lufu_allusion\data\processed\vocabularies\manual_parsed_results_tokens_ckip_reindexed.py.json"
match_json_path = r"D:\lufu_allusion\data\processed\ALL_match_results_jaccard.json"
output_json_path = fr"D:\lufu_allusion\data\processed\vocabularies\with_all_match_refs_{target_author}.json"
output_csv_path = fr"D:\lufu_allusion\outputs\figures\sentence_matches_{target_author}.csv"

# === ç¢ºä¿è¼¸å‡ºè³‡æ–™å¤¾å­˜åœ¨ ===
os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)

# === è¼‰å…¥ä¸»æª” JSON ===
with open(main_json_path, "r", encoding="utf-8") as f:
    main_data = json.load(f)

# === è¼‰å…¥ match æª”ä¸¦å»ºç«‹ç´¢å¼•è¡¨ {(article_num, sentence_num): [match_dict]} ===
with open(match_json_path, "r", encoding="utf-8") as f:
    match_data = json.load(f)

match_map = defaultdict(list)
for m in match_data:
    if m["author"] != target_author:
        continue
    key = (m["article_num"], m["sentence_num"])
    match_map[key].append({
        "matched_file": m["matched_file"],
        "matched_index": m["matched_index"],
        "matched": m["matched"],
        "similarity": m["similarity"]
    })

# === åˆä½µ matched_refsï¼Œåƒ…ä¿ç•™ç›®æ¨™è³¦å®¶çš„è³‡æ–™ ===
filtered_data = []
for article in main_data:
    if article.get("è³¦å®¶") != target_author:
        continue
    article_num = article.get("ç¯‡è™Ÿ")
for para in article.get("æ®µè½", []):
    if para.get("missing", False):
        print(f"â›” è·³éç¼ºå­—æ®µè½ï¼šç¯‡è™Ÿ {article.get('ç¯‡è™Ÿ')}ï¼Œæ®µè½ç·¨è™Ÿ {para.get('æ®µè½ç·¨è™Ÿ')}")
        continue
    for group in para.get("å¥çµ„", []):
        for sentence in group.get("å¥å­", []):
            key = (article_num, sentence["å¥ç·¨è™Ÿ"])
            if key in match_map:
                sentence["matched_refs"] = match_map[key]
    filtered_data.append(article)

# === å„²å­˜æ•´åˆå¾Œ JSON ===
with open(output_json_path, "w", encoding="utf-8") as f:
    json.dump(filtered_data, f, ensure_ascii=False, indent=2)

print(f"âœ… JSON æ•´åˆå®Œæˆï¼š{output_json_path}")

# === æ”¤å¹³ CSV ===
rows = []

for article in filtered_data:
    article_num = article["ç¯‡è™Ÿ"]
    author = article["è³¦å®¶"]
    title = article["è³¦ç¯‡"]

for para in article["æ®µè½"]:
    para_num = para["æ®µè½ç·¨è™Ÿ"]
    if para.get("missing", False):
        print(f"â›” è·³éç¼ºå­—æ®µè½ï¼ˆæ”¤å¹³ç•¥éï¼‰ï¼šç¯‡è™Ÿ {article_num}ï¼Œæ®µè½ç·¨è™Ÿ {para_num}")
        continue
    for group in para.get("å¥çµ„", []):
        group_num = group["å¥çµ„ç·¨è™Ÿ"]
        for sentence in group.get("å¥å­", []):
            sent_num = sentence["å¥ç·¨è™Ÿ"]
            original = sentence["åŸå§‹"]
            tokens = " ".join(sentence["tokens"])
            matched_refs = sentence.get("matched_refs", [])

            if matched_refs:
                for ref in matched_refs:
                    rows.append([
                        article_num, author, title,
                        para_num, group_num, sent_num,
                            original, tokens,
                            ref["matched_file"],
                            ref["matched_index"],
                            ref["matched"],
                            ref["similarity"]
                        ])
                else:
                    rows.append([
                        article_num, author, title,
                        para_num, group_num, sent_num,
                        original, tokens,
                        "", "", "", ""
                    ])

# === è¼¸å‡º CSV ===
with open(output_csv_path, "w", newline="", encoding="utf-8-sig") as f:
    writer = csv.writer(f)
    writer.writerow([
        "ç¯‡è™Ÿ", "è³¦å®¶", "è³¦ç¯‡", "æ®µè½ç·¨è™Ÿ", "å¥çµ„ç·¨è™Ÿ", "å¥ç·¨è™Ÿ",
        "åŸå§‹å¥", "tokens",
        "matched_file", "matched_index", "matched", "similarity"
    ])
    writer.writerows(rows)

print(f"ğŸ“„ å·²è¼¸å‡ºå®Œæ•´å¹³å¦åŒ– CSVï¼š{output_csv_path}")
